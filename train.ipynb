{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def create_3d_mpi_test_npz(input_file):\n",
        "    \"\"\"\n",
        "    Create 3D pose data for MPI dataset from a .npz file\n",
        "    Args:\n",
        "        input_file: path to the .npz file\n",
        "    Returns:\n",
        "        Normalized 3D poses, data mean, data std, and root positions\n",
        "    \"\"\"\n",
        "\n",
        "    mpii_to_human36 = np.array([6, 2, 1, 0, 3, 4, 5, 7, 8, 9, 13, 14, 15, 12, 11, 10])\n",
        "\n",
        "    # Load data from the .npz file\n",
        "    data = np.load(input_file)\n",
        "    joints_3d = data['S']  # 3D joint coordinates\n",
        "    img_name = data['imgname']  # Image names\n",
        "\n",
        "    # Map MPI joint indices to Human3.6M joint indices\n",
        "    poses = joints_3d[:, mpii_to_human36, :]\n",
        "    pose_neck = (poses[:, 8, :] + poses[:, 10, :]) / 2\n",
        "    poses_17 = np.insert(poses, 9, pose_neck, axis=1)\n",
        "    poses_mpi_to_h36 = copy.deepcopy(poses_17)\n",
        "\n",
        "    # Reshape poses to have them in a format compatible with H36M\n",
        "    poses_17 = np.reshape(poses_17, [poses_17.shape[0], -1])\n",
        "    poses_final = np.zeros([poses.shape[0], len(H36M_NAMES) * 3])\n",
        "\n",
        "    dim_to_use_x = np.where(np.array([x != '' for x in H36M_NAMES]))[0] * 3\n",
        "    dim_to_use_y = dim_to_use_x + 1\n",
        "    dim_to_use_z = dim_to_use_x + 2\n",
        "\n",
        "    dim_to_use = np.zeros(17 * 3, dtype=np.int32)\n",
        "    dim_to_use[0::3] = dim_to_use_x\n",
        "    dim_to_use[1::3] = dim_to_use_y\n",
        "    dim_to_use[2::3] = dim_to_use_z\n",
        "    poses_final[:, dim_to_use] = poses_17\n",
        "\n",
        "    test_set, test_root_positions = postprocess_3d_mpi(poses_final)\n",
        "    complete_test = copy.deepcopy(np.vstack(test_set))\n",
        "    data_mean, data_std, dim_to_ignore, dim_to_use_ = normalization_stats(complete_test, dim=3)\n",
        "\n",
        "    # Normalize the data\n",
        "    test_set = normalize_data_mpi(test_set, data_mean, data_std, dim_to_use_)\n",
        "    return test_set, data_mean, data_std, dim_to_ignore, dim_to_use_, test_root_positions, poses_mpi_to_h36, img_name\n",
        "\n",
        "\n",
        "def postprocess_3d_mpi(pose_3d):\n",
        "    \"\"\"\n",
        "    Process the 3D pose data with respect to the root joint (centering).\n",
        "    Args:\n",
        "        pose_3d: 3D pose data\n",
        "    Returns:\n",
        "        pose_3d_root: 3D pose data centered around the root joint\n",
        "        root_position: Original position of the root joint\n",
        "    \"\"\"\n",
        "\n",
        "    root_position = copy.deepcopy(pose_3d[:, :3])\n",
        "    pose_3d_root = pose_3d - np.tile(root_position, [1, len(H36M_NAMES)])\n",
        "\n",
        "    return pose_3d_root, root_position\n",
        "\n",
        "\n",
        "def normalize_data_mpi(data, mean, std, dim_to_use):\n",
        "    \"\"\"\n",
        "    Normalize the 3D pose data for MPI dataset\n",
        "    Args:\n",
        "        data: 3D pose data\n",
        "        mean: Mean of the data\n",
        "        std: Standard deviation of the data\n",
        "        dim_to_use: Dimensions to normalize\n",
        "    Returns:\n",
        "        Normalized data\n",
        "    \"\"\"\n",
        "\n",
        "    data = data[:, dim_to_use]\n",
        "    mean = mean[dim_to_use]\n",
        "    std = std[dim_to_use]\n",
        "    data_out = np.divide((data - mean), std + 1e-7)\n",
        "\n",
        "    return data_out\n",
        "\n"
      ],
      "metadata": {
        "id": "HDwQDtNIUINe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_2d_mpi_test_npz(input_file, Debug=False):\n",
        "    \"\"\"\n",
        "    Create 2D pose data as input for the stage two from an .npz file.\n",
        "    For the MPI dataset, this function uses the 2D joints provided in the dataset.\n",
        "\n",
        "    Args:\n",
        "        input_file: Path to the .npz file containing the MPI data.\n",
        "        Debug: Boolean, if True prints additional debugging information.\n",
        "\n",
        "    Returns:\n",
        "        test_set_2d: Normalized 2D test set data.\n",
        "        data_mean: Mean of the 2D pose data.\n",
        "        data_std: Standard deviation of the 2D pose data.\n",
        "        dim_to_use: Dimensions to use for further processing.\n",
        "    \"\"\"\n",
        "    mpii_to_human36 = np.array([6, 2, 1, 0, 3, 4, 5, 7, 8, 9, 13, 14, 15, 12, 11, 10])\n",
        "\n",
        "    # Load data from the .npz file\n",
        "    data = np.load(input_file)\n",
        "    joints = data['part']  # 2D joint coordinates\n",
        "\n",
        "    # Use only the corresponding joints\n",
        "    joints = joints[:, mpii_to_human36, :]\n",
        "\n",
        "    # Map the joint names to the appropriate Human3.6M structure\n",
        "    dim_to_use_x = np.where(np.array([x != '' and x != 'Neck/Nose' for x in H36M_NAMES]))[0] * 2\n",
        "    dim_to_use_y = dim_to_use_x + 1\n",
        "\n",
        "    dim_to_use = np.zeros(len(SH_NAMES) * 2, dtype=np.int32)\n",
        "    dim_to_use[0::2] = dim_to_use_x\n",
        "    dim_to_use[1::2] = dim_to_use_y\n",
        "\n",
        "    dimensions_to_ignore = np.delete(np.arange(len(H36M_NAMES) * 2), dim_to_use)\n",
        "    poses = np.reshape(joints, [joints.shape[0], -1])\n",
        "\n",
        "    poses_final = np.zeros([poses.shape[0], len(H36M_NAMES) * 2])\n",
        "    poses_final[:, dim_to_use] = poses\n",
        "\n",
        "    print(f'{poses_final.shape[0]} left from {poses.shape[0]} after filtering')\n",
        "\n",
        "    # Normalize the data\n",
        "    complete_train = copy.deepcopy(poses_final)\n",
        "    test_set_2d, data_mean, data_std = normalize_data_mpii(complete_train, dim_to_use)\n",
        "\n",
        "    if Debug:\n",
        "        print(\"Data has been normalized and debug mode is enabled.\")\n",
        "\n",
        "    return test_set_2d, data_mean, data_std, dim_to_use"
      ],
      "metadata": {
        "id": "94IKay_ksD50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generage_missing_data(enc_in,mis_number):\n",
        "  '''\n",
        "\n",
        "  enc_in: input 2d pose data\n",
        "  mis_number: the number of missing joints\n",
        "  return: 2d pose with missing joints randomly selected from the limbs\n",
        "  '''\n",
        "\n",
        "  joints_missing = [2, 3, 5, 6, 11, 12, 14, 15]    # only delete joints from limbs\n",
        "  for i in range(enc_in.shape[0]):\n",
        "    if mis_number == 1:\n",
        "      missing_index = random.randint(0, 7)\n",
        "      missing_dim = np.array([joints_missing[missing_index]*2, joints_missing[missing_index]*2+1])\n",
        "    else:\n",
        "      missing_index = random.sample(range(8), 2)\n",
        "      missing_dim = np.array([joints_missing[missing_index[0]] * 2, joints_missing[missing_index[0]] * 2 + 1,\n",
        "                              joints_missing[missing_index[1]] * 2, joints_missing[missing_index[1]] * 2 + 1])\n",
        "\n",
        "    enc_in[i, missing_dim] = 0.0       # get missing joints by setting the corresponding value to 0\n",
        "\n",
        "  return enc_in"
      ],
      "metadata": {
        "id": "vVV9mXR5sL62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Simple model to regress 3d human poses from 2d joint locations\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.python.ops import variable_scope as vs\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
        "import tensorflow as tf\n",
        "# import data_utils\n",
        "# import cameras as cam\n",
        "\n",
        "def kaiming(shape, dtype, partition_info=None):\n",
        "  \"\"\"Kaiming initialization as described in https://arxiv.org/pdf/1502.01852.pdf\n",
        "\n",
        "  Args\n",
        "    shape: dimensions of the tf array to initialize\n",
        "    dtype: data type of the array\n",
        "    partition_info: (Optional) info about how the variable is partitioned.\n",
        "      See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/init_ops.py#L26\n",
        "      Needed to be used as an initializer.\n",
        "  Returns\n",
        "    Tensorflow array with initial weights\n",
        "  \"\"\"\n",
        "  return(tf.truncated_normal(shape, dtype=dtype)*tf.sqrt(2/float(shape[0])))\n",
        "\n",
        "class LinearModel(object):\n",
        "  \"\"\" A simple Linear+RELU model \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               linear_size,\n",
        "               num_layers,\n",
        "               residual,\n",
        "               batch_norm,\n",
        "               max_norm,\n",
        "               batch_size,\n",
        "               learning_rate,\n",
        "               summaries_dir,\n",
        "               predict_14=False,\n",
        "               dtype=tf.float32):\n",
        "    \"\"\"Creates the linear + relu model\n",
        "\n",
        "    Args\n",
        "      linear_size: integer. number of units in each layer of the model\n",
        "      num_layers: integer. number of bilinear blocks in the model\n",
        "      residual: boolean. Whether to add residual connections\n",
        "      batch_norm: boolean. Whether to use batch normalization\n",
        "      max_norm: boolean. Whether to clip weights to a norm of 1\n",
        "      batch_size: integer. The size of the batches used during training\n",
        "      learning_rate: float. Learning rate to start with\n",
        "      summaries_dir: String. Directory where to log progress\n",
        "      predict_14: boolean. Whether to predict 14 instead of 17 joints\n",
        "      dtype: the data type to use to store internal variables\n",
        "    \"\"\"\n",
        "\n",
        "    # There are in total 17 joints in H3.6M and 16 in MPII (and therefore in stacked\n",
        "    # hourglass detections). We settled with 16 joints in 2d just to make models\n",
        "    # compatible (e.g. you can train on ground truth 2d and test on SH detections).\n",
        "    # This does not seem to have an effect on prediction performance.\n",
        "    self.HUMAN_2D_SIZE = 16 * 2\n",
        "\n",
        "    # In 3d all the predictions are zero-centered around the root (hip) joint, so\n",
        "    # we actually predict only 16 joints. The error is still computed over 17 joints,\n",
        "    # because if one uses, e.g. Procrustes alignment, there is still error in the\n",
        "    # hip to account for!\n",
        "    # There is also an option to predict only 14 joints, which makes our results\n",
        "    # directly comparable to those in https://arxiv.org/pdf/1611.09010.pdf\n",
        "    self.HUMAN_3D_SIZE = 14 * 3 if predict_14 else 16 * 3\n",
        "\n",
        "    self.input_size  = self.HUMAN_2D_SIZE\n",
        "    self.output_size = self.HUMAN_3D_SIZE\n",
        "\n",
        "    self.isTraining = tf.placeholder(tf.bool,name=\"isTrainingflag\")\n",
        "    self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
        "\n",
        "    # Summary writers for train and test runs\n",
        "    self.train_writer = tf.summary.FileWriter( os.path.join(summaries_dir, 'train' ))\n",
        "    self.test_writer  = tf.summary.FileWriter( os.path.join(summaries_dir, 'test' ))\n",
        "\n",
        "    self.linear_size   = linear_size\n",
        "    self.batch_size    = batch_size\n",
        "    self.learning_rate = tf.Variable( float(learning_rate), trainable=False, dtype=dtype, name=\"learning_rate\")\n",
        "    self.global_step   = tf.Variable(0, trainable=False, name=\"global_step\")\n",
        "    decay_steps = 100000  # empirical\n",
        "    decay_rate = 0.96     # empirical\n",
        "    self.learning_rate = tf.train.exponential_decay(self.learning_rate, self.global_step, decay_steps, decay_rate)\n",
        "    self.num_models = 5     # specify the number of gaussian kernels in the mixture model\n",
        "\n",
        "\n",
        "    # === Transform the inputs ===\n",
        "    with vs.variable_scope(\"inputs\"):\n",
        "\n",
        "      # === fix the batch size in order to introdoce uncertainty into loss ===#\n",
        "\n",
        "      enc_in  = tf.placeholder(dtype, shape=[None, self.input_size], name=\"enc_in\")\n",
        "      dec_out = tf.placeholder(dtype, shape=[None, self.output_size], name=\"dec_out\")\n",
        "\n",
        "\n",
        "      self.encoder_inputs  = enc_in\n",
        "      self.decoder_outputs = dec_out\n",
        "\n",
        "    # === Create the linear + relu combos ===\n",
        "    with vs.variable_scope( \"linear_model\" ):\n",
        "\n",
        "      # === First layer, brings dimensionality up to linear_size ===\n",
        "      w1 = tf.get_variable( name=\"w1\", initializer=kaiming, shape=[self.HUMAN_2D_SIZE, linear_size], dtype=dtype )\n",
        "      b1 = tf.get_variable( name=\"b1\", initializer=kaiming, shape=[linear_size], dtype=dtype )\n",
        "      w1 = tf.clip_by_norm(w1,1) if max_norm else w1\n",
        "      y3 = tf.matmul( enc_in, w1 ) + b1\n",
        "\n",
        "      if batch_norm:\n",
        "        y3 = tf.layers.batch_normalization(y3,training=self.isTraining, name=\"batch_normalization\")\n",
        "      y3 = tf.nn.relu( y3 )\n",
        "      y3 = tf.nn.dropout( y3, self.dropout_keep_prob )\n",
        "\n",
        "      # === Create multiple bi-linear layers ===\n",
        "      for idx in range( num_layers ):\n",
        "        y3 = self.two_linear( y3, linear_size, residual, self.dropout_keep_prob, max_norm, batch_norm, dtype, idx )\n",
        "\n",
        "\n",
        "\n",
        "      # === Last linear layer has HUMAN_3D_SIZE in output ===\n",
        "      w4 = tf.get_variable( name=\"w4\", initializer=kaiming, shape=[linear_size, self.HUMAN_3D_SIZE*self.num_models], dtype=dtype )\n",
        "      b4 = tf.get_variable( name=\"b4\", initializer=kaiming, shape=[self.HUMAN_3D_SIZE*self.num_models], dtype=dtype )\n",
        "      w4 = tf.clip_by_norm(w4,1) if max_norm else w4\n",
        "      y_mu = tf.matmul(y3, w4) + b4\n",
        "\n",
        "\n",
        "      w5 = tf.get_variable( name=\"w5\", initializer=kaiming, shape=[linear_size, self.num_models], dtype=dtype )\n",
        "      b5 = tf.get_variable( name=\"b5\", initializer=kaiming, shape=[self.num_models], dtype=dtype )\n",
        "      w5 = tf.clip_by_norm(w5,1) if max_norm else w5\n",
        "      y_sigma = tf.matmul(y3, w5) + b5\n",
        "      y_sigma = tf.nn.elu(y_sigma)+1\n",
        "\n",
        "      w6 = tf.get_variable( name=\"w6\", initializer=kaiming, shape=[linear_size, self.num_models], dtype=dtype )\n",
        "      b6 = tf.get_variable( name=\"b6\", initializer=kaiming, shape=[self.num_models], dtype=dtype )\n",
        "      y_alpha = tf.matmul(y3, w6) + b6\n",
        "      y_alpha = tf.nn.softmax(y_alpha, dim=1)\n",
        "\n",
        "      # === End linear model ===\n",
        "\n",
        "      components = tf.concat([y_mu, y_sigma, y_alpha], axis=1)\n",
        "      self.outputs = components\n",
        "\n",
        "    # add dirichlet conjucate prior to the mixing coefficents\n",
        "    prior = tf.constant([2.0, 2.0, 2.0, 2.0, 2.0], dtype=tf.float32)\n",
        "    loss_prior = Dirichlet_loss(components, self.HUMAN_3D_SIZE, self.num_models, prior)\n",
        "\n",
        "    with vs.variable_scope('loss'):\n",
        "\n",
        "        loss_gaussion = mean_log_Gaussian_like(dec_out, components, self.HUMAN_3D_SIZE, self.num_models)   # Mixture density network based on gaussian kernel\n",
        "        self.loss = loss_gaussion + loss_prior\n",
        "\n",
        "    tf.summary.scalar('loss', self.loss, collections=['train', 'test'])\n",
        "    self.loss_summary = tf.summary.merge_all('train')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # To keep track of the loss in mm\n",
        "    self.err_mm = tf.placeholder( tf.float32, name=\"error_mm\" )\n",
        "    self.err_mm_summary = tf.summary.scalar( \"loss/error_mm\", self.err_mm )\n",
        "\n",
        "    # Gradients and update operation for training the model.\n",
        "    opt = tf.train.AdamOptimizer( self.learning_rate )\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\n",
        "    with tf.control_dependencies(update_ops):\n",
        "\n",
        "      # Update all the trainable parameters\n",
        "      gradients = opt.compute_gradients(self.loss)\n",
        "      self.gradients = [[] if i==None else i for i in gradients]\n",
        "      self.updates = opt.apply_gradients(gradients, global_step=self.global_step)\n",
        "\n",
        "    # Keep track of the learning rate\n",
        "    self.learning_rate_summary = tf.summary.scalar('learning_rate/learning_rate', self.learning_rate)\n",
        "\n",
        "    # To save the model\n",
        "    self.saver = tf.train.Saver( tf.global_variables(), max_to_keep=None )\n",
        "\n",
        "\n",
        "  def two_linear( self, xin, linear_size, residual, dropout_keep_prob, max_norm, batch_norm, dtype, idx ):\n",
        "    \"\"\"\n",
        "    Make a bi-linear block with optional residual connection\n",
        "\n",
        "    Args\n",
        "      xin: the batch that enters the block\n",
        "      linear_size: integer. The size of the linear units\n",
        "      residual: boolean. Whether to add a residual connection\n",
        "      dropout_keep_prob: float [0,1]. Probability of dropping something out\n",
        "      max_norm: boolean. Whether to clip weights to 1-norm\n",
        "      batch_norm: boolean. Whether to do batch normalization\n",
        "      dtype: type of the weigths. Usually tf.float32\n",
        "      idx: integer. Number of layer (for naming/scoping)\n",
        "    Returns\n",
        "      y: the batch after it leaves the block\n",
        "    \"\"\"\n",
        "\n",
        "    with vs.variable_scope( \"two_linear_\"+str(idx) ) as scope:\n",
        "\n",
        "      input_size = int(xin.get_shape()[1])\n",
        "\n",
        "      # Linear 1\n",
        "      w2 = tf.get_variable( name=\"w2_\"+str(idx), initializer=kaiming, shape=[input_size, linear_size], dtype=dtype)\n",
        "      b2 = tf.get_variable( name=\"b2_\"+str(idx), initializer=kaiming, shape=[linear_size], dtype=dtype)\n",
        "      w2 = tf.clip_by_norm(w2,1) if max_norm else w2\n",
        "      y = tf.matmul(xin, w2) + b2\n",
        "      if  batch_norm:\n",
        "        y = tf.layers.batch_normalization(y,training=self.isTraining,name=\"batch_normalization1\"+str(idx))\n",
        "\n",
        "      y = tf.nn.relu( y )\n",
        "      y = tf.nn.dropout( y, dropout_keep_prob )\n",
        "\n",
        "      # Linear 2\n",
        "      w3 = tf.get_variable( name=\"w3_\"+str(idx), initializer=kaiming, shape=[linear_size, linear_size], dtype=dtype)\n",
        "      b3 = tf.get_variable( name=\"b3_\"+str(idx), initializer=kaiming, shape=[linear_size], dtype=dtype)\n",
        "      w3 = tf.clip_by_norm(w3,1) if max_norm else w3\n",
        "      y = tf.matmul(y, w3) + b3\n",
        "\n",
        "      if  batch_norm:\n",
        "        y = tf.layers.batch_normalization(y,training=self.isTraining,name=\"batch_normalization2\"+str(idx))\n",
        "\n",
        "      y = tf.nn.relu( y )\n",
        "      y = tf.nn.dropout( y, dropout_keep_prob )\n",
        "\n",
        "      # Residual every 2 blocks\n",
        "      y = (xin + y) if residual else y\n",
        "\n",
        "    return y\n",
        "\n",
        "  def step(self, session, encoder_inputs, decoder_outputs, dropout_keep_prob, isTraining=True):\n",
        "    \"\"\"Run a step of the model feeding the given inputs.\n",
        "\n",
        "    Args\n",
        "      session: tensorflow session to use\n",
        "      encoder_inputs: list of numpy vectors to feed as encoder inputs\n",
        "      decoder_outputs: list of numpy vectors that are the expected decoder outputs\n",
        "      dropout_keep_prob: (0,1] dropout keep probability\n",
        "      isTraining: whether to do the backward step or only forward\n",
        "\n",
        "    Returns\n",
        "      if isTraining is True, a 4-tuple\n",
        "        loss: the computed loss of this batch\n",
        "        loss_summary: tf summary of this batch loss, to log on tensorboard\n",
        "        learning_rate_summary: tf summary of learnign rate to log on tensorboard\n",
        "        outputs: predicted 3d poses\n",
        "      if isTraining is False, a 3-tuple\n",
        "        (loss, loss_summary, outputs) same as above\n",
        "    \"\"\"\n",
        "\n",
        "    input_feed = {self.encoder_inputs: encoder_inputs,\n",
        "                  self.decoder_outputs: decoder_outputs,\n",
        "                  self.isTraining: isTraining,\n",
        "                  self.dropout_keep_prob: dropout_keep_prob}\n",
        "\n",
        "    # Output feed: depends on whether we do a backward step or not.\n",
        "    if isTraining:\n",
        "      output_feed = [self.updates,       # Update Op that does SGD\n",
        "                     self.loss,\n",
        "                     self.loss_summary,\n",
        "                     self.learning_rate_summary,\n",
        "                     self.outputs]\n",
        "\n",
        "      outputs = session.run( output_feed, input_feed )\n",
        "      return outputs[1], outputs[2], outputs[3], outputs[4]\n",
        "\n",
        "    else:\n",
        "      output_feed = [self.loss, # Loss for this batch.\n",
        "                     self.loss_summary,\n",
        "                     self.outputs]\n",
        "\n",
        "      outputs = session.run(output_feed, input_feed)\n",
        "      return outputs[0], outputs[1], outputs[2]  # No gradient norm\n",
        "\n",
        "  def get_all_batches(self, data_x, data_y, camera_frame, training=True):\n",
        "      \"\"\"\n",
        "      Obtain a list of all the batches, randomly permutted\n",
        "      Args\n",
        "        data_x: dictionary with 2d inputs\n",
        "        data_y: dictionary with 3d expected outputs\n",
        "        camera_frame: whether the 3d data is in camera coordinates\n",
        "        training: True if this is a training batch. False otherwise.\n",
        "\n",
        "      Returns\n",
        "        encoder_inputs: list of 2d batches\n",
        "        decoder_outputs: list of 3d batches\n",
        "      \"\"\"\n",
        "\n",
        "      # Figure out how many frames we have\n",
        "      n = 0\n",
        "      repre = {}\n",
        "\n",
        "      for key2d in sorted(data_x.keys()):\n",
        "          n2d, _ = data_x[key2d].shape\n",
        "          n = n + n2d\n",
        "          repre[key2d] = n2d\n",
        "\n",
        "      encoder_inputs = np.zeros((n, self.HUMAN_2D_SIZE), dtype=float)\n",
        "      decoder_outputs = np.zeros((n, self.HUMAN_3D_SIZE), dtype=float)\n",
        "\n",
        "      # Put all the data into big arrays\n",
        "      idx = 0\n",
        "      for key2d in sorted(data_x.keys()):\n",
        "          (subj, b, fname) = key2d\n",
        "          # keys should be the same if 3d is in camera coordinates\n",
        "          key3d = key2d if (camera_frame) else (subj, b, '{0}.h5'.format(fname.split('.')[0]))\n",
        "          key3d = (subj, b, fname[:-3]) if fname.endswith('-sh') and camera_frame else key3d\n",
        "\n",
        "          n2d, _ = data_x[key2d].shape\n",
        "          encoder_inputs[idx:idx + n2d, :] = data_x[key2d]\n",
        "          decoder_outputs[idx:idx + n2d, :] = data_y[key3d]\n",
        "          idx = idx + n2d\n",
        "\n",
        "      if training:\n",
        "          # Randomly permute everything\n",
        "          idx = np.random.permutation(n)\n",
        "          encoder_inputs = encoder_inputs[idx, :]\n",
        "          decoder_outputs = decoder_outputs[idx, :]\n",
        "\n",
        "      # Make the number of examples a multiple of the batch size\n",
        "      n_extra = n % self.batch_size\n",
        "      if n_extra > 0:  # Otherwise examples are already a multiple of batch size\n",
        "          encoder_inputs = encoder_inputs[:-n_extra, :]\n",
        "          decoder_outputs = decoder_outputs[:-n_extra, :]\n",
        "\n",
        "      n_batches = n // self.batch_size\n",
        "      encoder_inputs = np.split(encoder_inputs, n_batches)\n",
        "      decoder_outputs = np.split(decoder_outputs, n_batches)\n",
        "      repre[sorted(data_x.keys())[-1]] = repre[sorted(data_x.keys())[-1]] - n_extra   ## track how many frames are used in each video,\n",
        "\n",
        "      return encoder_inputs, decoder_outputs, repre\n",
        "\n",
        "\n",
        "def mean_log_Gaussian_like(y_true, parameters,c,m ):\n",
        "    \"\"\"Mean Log Gaussian Likelihood distribution\n",
        "    y_truth: ground truth 3d pose\n",
        "    parameters: output of hypotheses generator, which conclude the mean, variance and mixture coeffcient of the mixture model\n",
        "    c: dimension of 3d pose\n",
        "    m: number of kernels\n",
        "    \"\"\"\n",
        "    components = tf.reshape(parameters, [-1, c + 2, m])\n",
        "    mu = components[:, :c, :]\n",
        "    sigma = components[:, c, :]\n",
        "    sigma = tf.clip_by_value(sigma, 1e-15,1e15)\n",
        "    alpha = components[:, c + 1, :]\n",
        "    alpha = tf.clip_by_value(alpha, 1e-8, 1.)\n",
        "\n",
        "    exponent = tf.log(alpha) - 0.5 * c * tf.log(2 * np.pi) \\\n",
        "               - c * tf.log(sigma) \\\n",
        "               - tf.reduce_sum((tf.expand_dims(y_true, 2) - mu) ** 2, axis=1) / (2.0 * (sigma) ** 2.0)\n",
        "\n",
        "    log_gauss = log_sum_exp(exponent, axis=1)\n",
        "    res = - tf.reduce_mean(log_gauss)\n",
        "    return res\n",
        "\n",
        "\n",
        "def Dirichlet_loss(parameters, c, m, prior):\n",
        "    '''\n",
        "    add dirichlet conjucate prior to the loss function to prevent all data fitting into single kernel\n",
        "    '''\n",
        "\n",
        "    components = tf.reshape(parameters, [-1, c + 2, m])\n",
        "    alpha = components[:, c + 1, :]\n",
        "    alpha = tf.clip_by_value(alpha, 1e-8, 1.)\n",
        "\n",
        "    loss = tf.reduce_sum((prior-1.0) * tf.log(alpha), axis=1)\n",
        "    res = -tf.reduce_mean(loss)\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def log_sum_exp(x, axis=None):\n",
        "    \"\"\"Log-sum-exp trick implementation\"\"\"\n",
        "    x_max = tf.reduce_max(x, axis=axis, keep_dims=True)\n",
        "    return tf.log(tf.reduce_sum(tf.exp(x - x_max),\n",
        "                       axis=axis, keep_dims=True))+x_max\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def mean_log_LaPlace_like(y_true, parameters, c, m):\n",
        "    \"\"\"Mean Log Laplace Likelihood distribution\n",
        "    parameters refer to mean_log_Gaussian_like\n",
        "    \"\"\"\n",
        "    components = tf.reshape(parameters, [-1, c + 2, m])\n",
        "    mu = components[:, :c, :]\n",
        "    sigma = components[:, c, :]\n",
        "    sigma = tf.clip_by_value(sigma, 1e-15, 1e15)\n",
        "    alpha = components[:, c + 1, :]\n",
        "    alpha = tf.clip_by_value(alpha, 1e-8, 1.)\n",
        "\n",
        "    exponent = tf.log(alpha) - c * tf.log(2.0 * sigma) \\\n",
        "               - tf.reduce_sum(tf.abs(tf.expand_dims(y_true, 2) - mu), axis=1) / (sigma)\n",
        "\n",
        "    log_gauss, _ = log_sum_exp(exponent, axis=1)\n",
        "    res = - tf.reduce_mean(log_gauss)\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "mIXjn8CGsOfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load('mpi_inf_3dhp_train.npz')\n",
        "\n",
        "# Access the arrays within the npz file\n",
        "img_names = data['imgname']\n",
        "centers = data['center']\n",
        "scales = data['scale']\n",
        "parts = data['part']\n",
        "S = data['S']\n"
      ],
      "metadata": {
        "id": "c-0AjV6zsTeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def process_npz_file(npz_file):\n",
        "    \"\"\"\n",
        "    Process the .npz file containing pose data.\n",
        "    Args:\n",
        "        npz_file: Path to the .npz file.\n",
        "    Returns:\n",
        "        data: Dictionary containing the processed data.\n",
        "    \"\"\"\n",
        "    # Load the data from the .npz file\n",
        "    data = np.load(npz_file)\n",
        "\n",
        "    # Extract the arrays from the .npz file\n",
        "    img_names = data['imgname']     # Image names\n",
        "    centers = data['center']        # Bounding box centers\n",
        "    scales = data['scale']          # Scales for normalization\n",
        "    parts = data['part']            # 2D joint positions\n",
        "    poses_3d = data['S']            # 3D joint positions\n",
        "\n",
        "    # Initialize the processed data dictionary\n",
        "    processed_data = {\n",
        "        'img_names': [],\n",
        "        'centers': [],\n",
        "        'scales': [],\n",
        "        '2D_joints': [],\n",
        "        '3D_joints': []\n",
        "    }\n",
        "\n",
        "    # Process and store the data\n",
        "    for i in range(len(img_names)):\n",
        "        img_name = img_names[i]\n",
        "        center = centers[i]\n",
        "        scale = scales[i]\n",
        "        joints_2d = parts[i]\n",
        "        joints_3d = poses_3d[i]\n",
        "\n",
        "        # Normalize 2D joints\n",
        "        joints_2d_norm = (joints_2d - center) / scale\n",
        "\n",
        "        # Center 3D joints around the root joint (joint 0 or hip)\n",
        "        joints_3d_centered = joints_3d - joints_3d[0]\n",
        "\n",
        "        # Store the processed data\n",
        "        processed_data['img_names'].append(img_name)\n",
        "        processed_data['centers'].append(center)\n",
        "        processed_data['scales'].append(scale)\n",
        "        processed_data['2D_joints'].append(joints_2d_norm)\n",
        "        processed_data['3D_joints'].append(joints_3d_centered)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "\n",
        "def save_processed_data(processed_data, output_file):\n",
        "    \"\"\"\n",
        "    Save the processed data to a new .npz file.\n",
        "    Args:\n",
        "        processed_data: Dictionary containing processed data.\n",
        "        output_file: Path to save the new .npz file.\n",
        "    \"\"\"\n",
        "    np.savez(output_file,\n",
        "             imgname=processed_data['img_names'],\n",
        "             center=processed_data['centers'],\n",
        "             scale=processed_data['scales'],\n",
        "             part=processed_data['2D_joints'],\n",
        "             S=processed_data['3D_joints'])\n",
        "\n",
        "    print(f\"Processed data saved to {output_file}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to the .npz file\n",
        "    npz_file = \"mpi_inf_3dhp_train.npz\"\n",
        "\n",
        "    # Process the .npz file\n",
        "    processed_data = process_npz_file(npz_file)\n",
        "\n",
        "    # Save the processed data to a new .npz file\n",
        "    save_processed_data(processed_data, \"processed_mpi_inf_3dhp.npz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2nJmJy_sx8I",
        "outputId": "f75e48ef-5f8b-456a-f3b5-6754fc3a0478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data saved to processed_mpi_inf_3dhp.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PoseDataset(Dataset):\n",
        "    def __init__(self, npz_file):\n",
        "        # Load the .npz file\n",
        "        data = np.load(npz_file)\n",
        "\n",
        "        self.img_names = data['imgname']\n",
        "        self.centers = data['center']\n",
        "        self.scales = data['scale']\n",
        "        self.joints_2d = data['part']\n",
        "        self.joints_3d = data['S']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_names[idx]\n",
        "        center = self.centers[idx]\n",
        "        scale = self.scales[idx]\n",
        "        joints_2d = self.joints_2d[idx]\n",
        "        joints_3d = self.joints_3d[idx]\n",
        "\n",
        "        # Preprocess data here if necessary (e.g., normalize or augment)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        joints_2d = torch.tensor(joints_2d, dtype=torch.float32)\n",
        "        joints_3d = torch.tensor(joints_3d, dtype=torch.float32)\n",
        "\n",
        "        return joints_2d, joints_3d\n"
      ],
      "metadata": {
        "id": "oILafvPNtli3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MDNLayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_gaussians):\n",
        "        super(MDNLayer, self).__init__()\n",
        "        self.z_pi = nn.Linear(input_size, num_gaussians)\n",
        "        self.z_sigma = nn.Linear(input_size, num_gaussians * output_size)\n",
        "        self.z_mu = nn.Linear(input_size, num_gaussians * output_size)\n",
        "        self.num_gaussians = num_gaussians\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        pi = F.log_softmax(self.z_pi(x), dim=-1)  # Mixing coefficients\n",
        "        sigma = torch.exp(self.z_sigma(x))        # Standard deviations\n",
        "        mu = self.z_mu(x)                         # Means\n",
        "        return pi, sigma, mu\n",
        "\n",
        "class MDNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_gaussians):\n",
        "        super(MDNModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.mdn = MDNLayer(256, output_size, num_gaussians)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        pi, sigma, mu = self.mdn(x)\n",
        "        return pi, sigma, mu\n"
      ],
      "metadata": {
        "id": "_J2WtrdbusC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class PoseDataset(Dataset):\n",
        "    def __init__(self, npz_file):\n",
        "        # Load the data from the .npz file\n",
        "        data = np.load(npz_file)\n",
        "        self.img_names = data['imgname']\n",
        "        self.centers = data['center']\n",
        "        self.scales = data['scale']\n",
        "        self.joints_2d = data['part']  # 2D joints\n",
        "        self.joints_3d = data['S']     # 3D joints\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.joints_2d)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Normalize 2D and center 3D data\n",
        "        center = self.centers[idx]\n",
        "        scale = self.scales[idx]\n",
        "        joints_2d = (self.joints_2d[idx] - center) / scale\n",
        "        joints_3d = self.joints_3d[idx] - self.joints_3d[idx][0]  # Centering on root joint\n",
        "\n",
        "        return torch.FloatTensor(joints_2d), torch.FloatTensor(joints_3d)\n",
        "\n",
        "# Create a data loader for training\n",
        "def get_dataloader(npz_file, batch_size, shuffle=True):\n",
        "    dataset = PoseDataset(npz_file)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
      ],
      "metadata": {
        "id": "iCuJmO91vGws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# from model import MDNModel\n",
        "# from dataloader import get_dataloader\n",
        "\n",
        "def mdn_loss(pi, sigma, mu, target):\n",
        "    m = torch.distributions.Normal(mu, sigma)\n",
        "    prob = torch.exp(m.log_prob(target.unsqueeze(1))).prod(2)\n",
        "    loss = -torch.mean(torch.logsumexp(torch.log(pi) + torch.log(prob), dim=1))\n",
        "    return loss\n",
        "\n",
        "def train_model(npz_file, epochs, batch_size, num_gaussians, lr):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load dataset\n",
        "    dataloader = get_dataloader(npz_file, batch_size)\n",
        "\n",
        "    # Define model, optimizer, and loss function\n",
        "    input_size = 34  # Assuming 17 joints * 2 (for 2D)\n",
        "    output_size = 51  # Assuming 17 joints * 3 (for 3D)\n",
        "    model = MDNModel(input_size, output_size, num_gaussians).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (joints_2d, joints_3d) in enumerate(dataloader):\n",
        "            joints_2d, joints_3d = joints_2d.to(device), joints_3d.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            pi, sigma, mu = model(joints_2d)\n",
        "            loss = mdn_loss(pi, sigma, mu, joints_3d)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(dataloader)}\")\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(model.state_dict(), 'mdn_pose_estimation.pth')\n",
        "    print(\"Model saved as mdn_pose_estimation.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    npz_file = \"processed_mpi_inf_3dhp.npz\"  # Your processed dataset\n",
        "    epochs = 50\n",
        "    batch_size = 32\n",
        "    num_gaussians = 5\n",
        "    lr = 0.001\n",
        "\n",
        "    train_model(npz_file, epochs, batch_size, num_gaussians, lr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "fRquLjMcvPMc",
        "outputId": "7a47cdc3-0692-40d9-a533-74d59b4d34a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5067d5cca913>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gaussians\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-5067d5cca913>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(npz_file, epochs, batch_size, num_gaussians, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Define model, optimizer, and loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-39e4bf14d2e6>\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(npz_file, batch_size, shuffle)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPoseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpz_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "npz_file = \"mpi_inf_3dhp_train.npz\"\n",
        "data = np.load(npz_file)\n",
        "\n",
        "print(\"Keys in the .npz file:\", data.keys())\n",
        "print(\"Number of 2D joints:\", len(data['part']))\n",
        "print(\"Number of 3D joints:\", len(data['S']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQRVgqegv7Pr",
        "outputId": "1523cf92-6cc4-4681-9028-b29dc6b637d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in the .npz file: KeysView(NpzFile 'mpi_inf_3dhp_train.npz' with keys: imgname, center, scale, part, S)\n",
            "Number of 2D joints: 0\n",
            "Number of 3D joints: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8qN4BEuvwS84"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}